import google.generativeai as genai
import os
from dotenv import load_dotenv
from google.ai.generativelanguage import GoogleSearchRetrieval

# Cargar variables de entorno
load_dotenv(override=True) # A√±adir override=True para sobrescribir variables existentes

# Configurar credenciales de Google Application Credentials desde un archivo JSON
credentials_path_from_env_file = os.getenv("GOOGLE_APPLICATION_CREDENTIALS_PATH")
effective_credentials_path = None

if credentials_path_from_env_file:
    if os.path.exists(credentials_path_from_env_file):
        os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = credentials_path_from_env_file
        effective_credentials_path = credentials_path_from_env_file
        print(f"Usando credenciales de servicio desde el archivo: {effective_credentials_path}")
    else:
        raise FileNotFoundError(
            f"El archivo de credenciales JSON especificado en GOOGLE_APPLICATION_CREDENTIALS_PATH ({credentials_path_from_env_file}) no se encontr√≥."
        )
elif os.getenv("GOOGLE_APPLICATION_CREDENTIALS"):
    effective_credentials_path = os.getenv("GOOGLE_APPLICATION_CREDENTIALS")
    if not os.path.exists(effective_credentials_path):
        print(f"Advertencia: El archivo de credenciales JSON especificado por la variable de entorno GOOGLE_APPLICATION_CREDENTIALS ({effective_credentials_path}) no se encontr√≥, pero se intentar√° usar.")
    else:
        print(f"Usando credenciales de servicio desde la variable de entorno GOOGLE_APPLICATION_CREDENTIALS: {effective_credentials_path}")
else:
    raise ValueError(
        "No se encontraron credenciales de Google. "
        "Define GOOGLE_APPLICATION_CREDENTIALS_PATH en tu archivo .env apuntando a tu archivo de credenciales JSON, "
        "o configura la variable de entorno GOOGLE_APPLICATION_CREDENTIALS directamente en tu sistema."
    )

# Configurar la API de Gemini.
# Al no pasar api_key, la librer√≠a usar√° Application Default Credentials (ADC),
# que recoger√° las credenciales del archivo JSON especificado por GOOGLE_APPLICATION_CREDENTIALS.
try:
    genai.configure() # No se pasa api_key, usar√° ADC
except Exception as e:
    print(f"Error al configurar genai con Application Default Credentials: {e}")
    raise RuntimeError(
        "No se pudo configurar la API de Gemini con las credenciales proporcionadas. "
        "Verifica que el archivo de credenciales es v√°lido y que la cuenta de servicio tiene los permisos necesarios (ej. 'Vertex AI User')."
    ) from e

# --- Configuraci√≥n del Asistente Virtual NEAE ---

# Selecciona el modelo.
MODEL_NAME = "gemini-1.5-pro-latest"

def cargar_prompt_desde_archivo(ruta_archivo):
    """Carga el contenido de un archivo de texto."""
    try:
        with open(ruta_archivo, 'r', encoding='utf-8') as f:
            return f.read()
    except FileNotFoundError:
        print(f"Error: No se encontr√≥ el archivo de prompt en {ruta_archivo}")
        return None
    except Exception as e:
        print(f"Error al leer el archivo de prompt: {e}")
        return None

# Cargar el prompt de sistema desde prompt.txt
# Aseg√∫rate de que prompt.txt est√© en el mismo directorio que asistente-virtual.py o proporciona la ruta completa.
RUTA_PROMPT_TXT = os.path.join(os.path.dirname(__file__), "prompt.txt")
SYSTEM_PROMPT_ASISTENTE_NEAE = cargar_prompt_desde_archivo(RUTA_PROMPT_TXT)

if not SYSTEM_PROMPT_ASISTENTE_NEAE:
    raise ValueError("No se pudo cargar el prompt del sistema desde prompt.txt. Verifica el archivo y la ruta.")

# --- Funciones del Asistente ---

def inicializar_modelo():
    """Inicializa el modelo generativo de Gemini."""
    try:
        # Configurar la herramienta de b√∫squeda de Google
        google_search_tool = GoogleSearchRetrieval()

        model = genai.GenerativeModel(
            MODEL_NAME,
            system_instruction=SYSTEM_PROMPT_ASISTENTE_NEAE, # Usamos el prompt cargado de prompt.txt
            tools=[google_search_tool] # Habilitar la b√∫squeda en Google
        )
        return model
    except Exception as e:
        print(f"Error al inicializar el modelo: {e}")
        return None

def iniciar_chat(model):
    """Inicia una sesi√≥n de chat con el modelo."""
    if model:
        chat = model.start_chat(history=[]) # Historial vac√≠o para empezar
        return chat
    return None

def preguntar_al_asistente(chat_session, pregunta_usuario):
    """Env√≠a una pregunta al chat y obtiene una respuesta."""
    if not chat_session:
        return "Error: La sesi√≥n de chat no est√° iniciada."
    try:
        print("ü§ñ Asistente NEAE est√° pensando...")
        response = chat_session.send_message(pregunta_usuario)
        # El descargo de responsabilidad y la leyenda de iconos deben ser manejados por el LLM
        # seg√∫n las instrucciones en prompt.txt
        return response.text
    except Exception as e:
        return f"Error al comunicarse con el modelo: {e}"

# --- Interfaz de Usuario Simple (Consola) ---
if __name__ == "__main__":
    print("Iniciando Asistente Virtual NEAE...")
    modelo_gemini = inicializar_modelo()

    if not modelo_gemini:
        print("No se pudo iniciar el asistente. Revisa la configuraci√≥n, la API Key y el archivo prompt.txt.")
    else:
        chat_sesion = iniciar_chat(modelo_gemini)
        if not chat_sesion:
            print("No se pudo iniciar la sesi√≥n de chat.")
        else:
            # Mostrar directamente el mensaje de inicio especificado por el usuario
            print("\\nüìù Para poder ayudarte de la forma m√°s precisa y √∫til posible, necesito que me indiques:")
            print("")
            print("- **El curso o etapa educativa** (Infantil, Primaria, Secundaria o FP).")
            print("- **El tipo de NEAE** (por ejemplo: TDAH, dislexia, TEA, discapacidad auditiva, motora, etc.).")
            print("")
            print("Una vez que tenga esta informaci√≥n, podr√© ofrecerte propuestas, recursos y adaptaciones espec√≠ficas y fundamentadas en la normativa vigente de Andaluc√≠a. ¬°Gracias! üìò‚ú®")
            print("---")
            print("Escribe 'salir' para terminar la conversaci√≥n.")
            # print("---") # Eliminado un separador extra para que coincida con el formato solicitado

            while True:
                pregunta = input("üë§ T√∫: ")
                if pregunta.lower() == 'salir':
                    print("ü§ñ Asistente NEAE: ¬°Hasta pronto! Espero haberte sido de ayuda.")
                    break
                if pregunta.strip():
                    respuesta = preguntar_al_asistente(chat_sesion, pregunta)
                    print(f"ü§ñ Asistente NEAE:\\n{respuesta}\\n---")
                else:
                    print("ü§ñ Asistente NEAE: Por favor, escribe una pregunta.")